 running ML atop GPUs, specifically about multiplexing many GPUs across jobs. It is a very interesting paper.
Last summer paper. 
Multr-tenant ML (Gandiva)
GPU properties
ML jobs fine-grained properties
constraints, objective.
------------------------
GPU armple parallelism.
batch size of images. 
--------------------------
multri-GPU machines.
1.PCIe  2.Nvlink (irregular)+ PCIe â‰ˆ 25 GB
GPU to GPU links.
> (faster) network.
some are PCIE machine ; some are cluster machines.
Job Group 1,
JG2,
---------------------------------
Linited GPU 1.Efficiency | 2.Virtualize
------------------------------------
(1) Network - communication bound
(2) Memory is a coslimit.
(3) Periordic | iterate ---> Predictable

evaluate should decusion.
(4) Recursion Use.
suspending rame | nytubum
------------------------------------
Communication? --> scheduling work  --> reactive. (as many as free GPU as possible)
job --- How many cansdidated GPUs.
1.CPU socket  2. machine  3.Only free GPU.

summary : introspectively.

this is all the machinism for 
GPU applications for jobs, using migration.

------------------------
compare with tensorflow.

